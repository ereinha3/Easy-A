Easy A
Programmers Documentation

Morgan Jones

Source Files
-------------
Source files consist of code used to run the softwares critical functions and stored in the src/ directory.

context.py - A very simple program that changes the working directory of any file which imports. 

dataAccess.py - Consists of a series of functions used to query the gradeData.py file. Graphing queries are accessed through the function query_graphing_data. Other helper functions are used as needed by the GUI to dynamically generate prompts, or in testing functions to gather and test data.

processData.py - A procedure that reads a gradedata.js file (taken from the daily emerald) and converts it into a python dictionary. That dictionary is stored as the file gradeData.py. This program also performs any modifications to the data format as needed to optimize search queries on the dataset, or to expand the search queries possible on the dataset. Currently processData splits the gradedata.js entry keys from "departmentCourseNumber" -> "department": { courseNumber: ...}. The advantage of this is that we can index into a specific department in O(1) time and gather data from that department extremely quickly. This also simplified the control flow of querying functions.

scraper.py - A program which uses BeautifulSoup to scrape data from the University of Oregon department webpages for natural sciences. The scraper returns a list of faculty names for department webpages.

nameMatch.py - A program that compares a list of faculty_names gathered from the scraper to some instructor name queried by the dataAccess.py queries. Note, the structure of instructor names provided in gradedata.js is entirely different than the structure of faculty names as listed on the UO department websites. The faculty names gathered from the scraper are listed "first middle last", whereas the names in gradedata.js are listed "last, first middle". Some instructors had multiple middle and last names, and some instructors have only initials listed for one or more names (but the faculty listing might have included the full name instead of an initial, or the faculty name included only an initial and the gradedata.js included a full name). These issues made name matching quite difficult. A multilayered approach of organizing scraped faculty names by last name first, and then iteratively comparing against an instructors set of full names was used.
 
workingGUI.py - The user-facing program that loads a GUI interface in a Tkinter frame.

graphFramePacker.py - 

Data Files
----------
Files in the src/data/ directory are raw data files. These data files are queried and acted upon by programs in the src/ directory.

gradedata.js - The base data file provided by the daily emerald.

gradeData.py - A python dictionary converted from gradedata.js and populated by running the processData.py script. The data is stored in a python dictionary so that it can be easily imported and accessed with python functions. The dictionary structure has been slightly optimized from the original gradedata.js format. But the actual data included should be a complete match. Note, our gradeData.py file includes data from all departments, but our implementation only leverages data from the natural science departments. Including the full departments lists was simpler and just as performant, and allows easier expansion of the program to include other departments if necessary.

facultyNames.py - A dictionary of faculty names organized by last name. These are populated by running the scraper.py script.

Test Files
----------
Files in the src/test/ directory includes a test on name matching, since the process of matching names was quite involved and complicated (and the structure of names gathered spotty and inconsistent).

testNameMatch.py - 

